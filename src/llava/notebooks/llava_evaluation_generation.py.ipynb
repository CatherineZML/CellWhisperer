{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e637bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import anndata\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import process_images, load_image_from_base64, tokenizer_image_token\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava import conversation as conversation_lib\n",
    "\n",
    "\n",
    "\n",
    "from llava.train.train import LazySupervisedDataset, DataArguments, DataCollatorForSupervisedDataset\n",
    "import torch\n",
    "from transformers import Trainer, EvalPrediction\n",
    "import transformers\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model_dir = snakemake.input.llava_model # \"/msc/home/mschae83/cellwhisperer/results/llava/finetuned/Mistral-7B-Instruct-v0.2__03jujd8s/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37134b0-f656-42d7-b354-f81516e5c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45f2d5-91bb-4810-abf1-8986608de803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name=get_model_name_from_path(model_dir)\n",
    "assert \"mistral\" in model_name.lower() and \"__\" in model_name, \"sure that you are not using a mistral model? LLaVA depends on having it in the name (if it is mistral)\"\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_dir, model_base=None, model_name=model_name, load_8bit=False, load_4bit=False, device=\"cuda\", use_flash_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e3a8e-5c3f-41c7-88ac-863727a59b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(snakemake.input.adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef99a8-bdc0-4b4c-9d8c-4afa8af16596",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"index_int\"] = list(range(len(adata.obs)))\n",
    "grouped_embeddings = adata.obs.groupby(\"leiden\", observed=True).apply(lambda group: adata.X[group.index_int].mean(axis=0), include_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292b50e-bbc3-4fd0-bae7-c7f9d9cfd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "(adata.obs.leiden == \"0\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef61e76-38f7-4db5-8cfd-00547721ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ecc842-283d-479f-868d-33d828c3a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_lib.default_conversation = conversation_lib.conv_templates[\"mistral_instruct\"]\n",
    "\n",
    "prompt = snakemake.params[\"request\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a51e8c-3f62-4f86-998c-3db0e3ff6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {}\n",
    "for leiden_id, grouped_embedding in grouped_embeddings.items():\n",
    "    images = torch.tensor(grouped_embedding, device=model.device, dtype=torch.float16)  # float16 is the way in llava apparently\n",
    "    \n",
    "    if \"image\" not in prompt:\n",
    "        prompt = prompt + \"\\n<image>\"\n",
    "    # Should be a noop, but kept for compatibility\n",
    "    replace_token = DEFAULT_IMAGE_TOKEN\n",
    "    if getattr(model.config, 'mm_use_im_start_end', False): \n",
    "        replace_token = DEFAULT_IM_START_TOKEN + replace_token + DEFAULT_IM_END_TOKEN\n",
    "    prompt = prompt.replace(DEFAULT_IMAGE_TOKEN, replace_token)\n",
    "     \n",
    "    num_tokens = int(re.match(r'^mlp(\\d+)x_(\\d+)t_gelu$', model.config.mm_projector_type).group(2))\n",
    "    num_image_tokens = prompt.count(replace_token) * num_tokens\n",
    "    image_args = {\"images\": images, \"image_sizes\": None}\n",
    "    \n",
    "    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)\n",
    "    \n",
    "    generated_tokens = model.generate(\n",
    "        inputs=input_ids,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        num_beams=snakemake.params.num_beams,\n",
    "        top_p=1.0,\n",
    "        max_new_tokens=256,\n",
    "        use_cache=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # explicitly request open-ended generation (suppresses warnings)\n",
    "        **image_args\n",
    "    )\n",
    "    generated_text = tokenizer.decode(generated_tokens[0], skip_prompt=True, skip_special_tokens=True, timeout=15)\n",
    "    print(generated_text[:80] + \"...\")\n",
    "    cluster_labels[leiden_id] = generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f87a45-1de8-4247-a141-ebf3deb72644",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.Series(cluster_labels)\n",
    "out.index.name=\"leiden\"\n",
    "out.name=\"annotation\"\n",
    "\n",
    "out.to_csv(snakemake.output.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5955ee2-e4f2-450a-ab96-e0ad86abd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
