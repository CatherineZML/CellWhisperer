{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e637bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(snakemake.threads)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import anndata\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import process_images, load_image_from_base64, tokenizer_image_token\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava import conversation as conversation_lib\n",
    "\n",
    "\n",
    "\n",
    "from llava.train.train import LazySupervisedDataset, DataArguments, DataCollatorForSupervisedDataset\n",
    "from transformers import Trainer, EvalPrediction\n",
    "import transformers\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = snakemake.input.llava_model # \"/msc/home/mschae83/cellwhisperer/results/llava/finetuned/Mistral-7B-Instruct-v0.2__03jujd8s/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37134b0-f656-42d7-b354-f81516e5c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45f2d5-91bb-4810-abf1-8986608de803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "model_name=get_model_name_from_path(model_dir)\n",
    "assert \"mistral\" in model_name.lower() and \"__\" in model_name, \"sure that you are not using a mistral model? LLaVA depends on having it in the name (if it is mistral)\"\n",
    "\n",
    "logging.info(f\"Loading model {model_name}\")\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_dir, model_base=None, model_name=model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e3a8e-5c3f-41c7-88ac-863727a59b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Loading data\")\n",
    "adata = anndata.read_h5ad(snakemake.input.embedding_adata)\n",
    "logging.info(f\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97484168-e81d-4eb7-b59d-6b849c6c6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Loading read count data\")\n",
    "read_count_adata = anndata.read_h5ad(snakemake.input.read_count_adata, backed=\"r\")\n",
    "logging.info(f\"Read count data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf52c6-092d-4736-b8f8-914ed1b1df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (adata.obs.orig_ids == read_count_adata.obs.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef99a8-bdc0-4b4c-9d8c-4afa8af16596",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"index_int\"] = list(range(len(adata.obs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292b50e-bbc3-4fd0-bae7-c7f9d9cfd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "(adata.obs.leiden == \"0\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ecc842-283d-479f-868d-33d828c3a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_lib.default_conversation = conversation_lib.conv_templates[\"mistral_instruct\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a51e8c-3f62-4f86-998c-3db0e3ff6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_annotation(cluster_values: np.array) -> pd.Series:\n",
    "    prompt = snakemake.params[\"request\"]\n",
    "    grouped_embeddings = adata.obs.groupby(cluster_values, observed=True).apply(lambda group: adata.X[group.index_int].mean(axis=0), include_groups=False)\n",
    "    cluster_labels = {}\n",
    "    for cluster_id, grouped_embedding in grouped_embeddings.items():\n",
    "        images = torch.tensor(grouped_embedding, device=model.device, dtype=torch.bfloat16)  # float16 is the way in llava apparently\n",
    "        \n",
    "        if \"image\" not in prompt:\n",
    "            prompt = prompt + \"\\n<image>\"\n",
    "        # Should be a noop, but kept for compatibility\n",
    "        replace_token = DEFAULT_IMAGE_TOKEN\n",
    "        if getattr(model.config, 'mm_use_im_start_end', False): \n",
    "            replace_token = DEFAULT_IM_START_TOKEN + replace_token + DEFAULT_IM_END_TOKEN\n",
    "        prompt = prompt.replace(DEFAULT_IMAGE_TOKEN, replace_token)\n",
    "         \n",
    "        image_args = {\"images\": images, \"image_sizes\": None}\n",
    "        logging.info(f\"Generating input_ids for cluster {cluster_id}\")\n",
    "        input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)\n",
    "        logging.info(f\"Generated input_ids cluster {cluster_id}\")\n",
    "        logging.info(f\"Generating for cluster {cluster_id}\")\n",
    "        generated_tokens = model.generate(\n",
    "            inputs=input_ids,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            num_beams=snakemake.params.num_beams,\n",
    "            top_p=1.0,\n",
    "            max_new_tokens=256,\n",
    "            use_cache=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,  # explicitly request open-ended generation (suppresses warnings)\n",
    "            **image_args\n",
    "        )\n",
    "        logging.info(f\"Generated for cluster {cluster_id}\")\n",
    "        generated_text = tokenizer.decode(generated_tokens[0], skip_prompt=True, skip_special_tokens=True, timeout=15)\n",
    "        print(generated_text[:80] + \"...\")\n",
    "        cluster_labels[cluster_id] = generated_text\n",
    "    out = pd.Series(cluster_labels)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec821d-e604-40b1-bb8b-16a724f5da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "cluster_series = {\"leiden\": adata.obs[\"leiden\"].values}\n",
    "try:\n",
    "    for cluster_field in read_count_adata.uns[\"cluster_fields\"]:\n",
    "        cluster_series[cluster_field] = read_count_adata.obs[cluster_field].values\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "logging.info(f\"Starting cluster annotation\")\n",
    "for cluster_field, cluster_values in cluster_series.items():\n",
    "    logging.info(f\"Starting cluster annotation for {cluster_field}\")\n",
    "    out = cluster_annotation(cluster_values)\n",
    "    logging.info(f\"Finished cluster annotation for {cluster_field}\")\n",
    "    out.index.name = \"cluster_values\"\n",
    "    out.name = \"cluster_annotations\"\n",
    "    out = out.to_frame()\n",
    "    out[\"cluster_field\"] = cluster_field\n",
    "    dfs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f87a45-1de8-4247-a141-ebf3deb72644",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs).to_csv(snakemake.output.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
